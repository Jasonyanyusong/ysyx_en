[#](#Expression-evaluation) Expression evaluation
=================

In TRM, the values in the registers (including the PC) and memory uniquely determine one unique state of the computer. So it stands to reason that printing the registers and scanning the memory must be able to help us debug all the problems. But for ease of use, we also want the simple debugger to help us compute expressions with registers and memory. That's why you need to add expression evaluation functionality to the simple debugger. For the sake of simplicity, let's consider the implementation of math expression evaluation first.

### [#](#Mathematical-expression-evaluation) Mathematical expression evaluation

You are given a string of expressions

    "5 + 4 * 3 / 2 - 1"
    

How do you find its value? Expression evaluation is such a classic problem that there are many ways to solve it. We have weighed the knowledge required against the difficulty, and here we use the following approach to solving expression evaluation: 

1. first identify all the units in the expression
2. recursively evaluate the expression according to its inductive definition.

#### [#](#Lexical-Analysis) Lexical Analysis

"Lexical analysis" is a fancy word for doing the first thing above, "identifying all the units in an expression". A "unit" in this case is a substring with its own meaning, formally known as a token. Specifically, we need to identify the tokens `5`, `+`, `4`, `*`, `3`, `/`, `2`, `-`, and `1` in the above expression. You might think that's a pretty simple thing to do, but consider the following expression.

    "0x80100000+   ($a0 +5)*4 - *(  $t1 + 8) + number"
    

It contains many more features, such as hexadecimal integers (`0x80100000`), parentheses, access to registers (`$a0`), pointer dereferencing (the second `*`), and access to variables (`number`). In fact, such complex expressions are often used during debugging, and you need to be able to correctly recognize tokens with a variable number of spaces (zero or more). Of course, you can still do this manually (if you like challenging work), and a quicker and easier way to do it is to use regular expressions. Regular expressions make it easy to match complex patterns and are a must for programmers. If you've never encountered regular expressions before, please STFW. In the experiment, you just need to understand some basic knowledge of regular expressions (such as metacharacters).

Once you've learned how to use simple regular expressions, you can start thinking about how to use regular expressions to recognize tokens. Let's start with a simple case - an arithmetic expression, where only the following token types are allowed in the expression to be evaluated.
* decimal integers
* `+`, `-`, `*`, `/`
* `(`, `)`.
* A collection of spaces  (one or more spaces).

First we need to write rules to recognize each of these token types using regular expressions. In the framework code, a rule is a pair (implemented with C struct) consisting of a regular expression and a token type. The framework code already gives rules for `+` and collection of spaces, where the token type for collection of spaces is `TK_NOTYPE`, since collection of spaces don't take part in the evaluation process and can be discarded once recognized, and the token type for `+` is `'+'`. In fact, the token type is just an integer, so just make sure that different types of tokens are encoded as different integers. There is also a rule in the framework code that recognizes double equals signs, but we can ignore it for now.

These rules are compiled via `init_regex()` during the initialization of the simple debugger into some internal data structure for pattern matching, which are used by the library functions, and which are used over and over again, but you don't have to worry about how they are organized. However, if the compilation of the regular expression fails, NEMU will trigger an assertion fail, in which case you need to check that the rules you've written conform to the syntax of the regular expression.

Given an expression to be evaluated, we first need to recognize the tokens in it, and this is done by the `make_token()` function. The `make_token()` function works in a very straightforward way, it uses the `position` variable to indicate where it is currently processing, and it tries to match the string at the current position with all the rules in order. When a rule matches successfully, and the matched substring is exactly where `position` is, we have successfully recognized a token, and the `Log()` macro outputs a message that the recognition was successful. All you need to do is save the information about the recognized token (with the exception of the space string), and we use the `Token` structure to save the token information:

    typedef struct token {
      int type;
      char str[32];
    } Token;
    

The `type` member is used to record the type of the token. For most tokens it is sufficient to just record the type, e.g. `+`, `-`, `*`, `/`, but this is not sufficient for some tokens: if we only record the type of a decimal integer token, then when evaluating the token we will still have no idea of what the decimal integer is. We should record the corresponding substring of the token, and the `str` member is used to do this. Note that the `str` member has a finite length, so when you realize that the buffer is about to overflow, you should handle it accordingly (think about it, how would you handle it?) , otherwise it will result in some hard to find bug. The `tokens` array is used to store the recognized tokens in order, and `nr_token` indicates the number of recognized tokens.

If all the rules tried can not match the token at the current position, the recognition fails, and the framework code outputs the current position of the token (when the expression is too long and requires line breaks in the terminal, `^` may not indicate the correct position, and it is recommended to locate the position of the token by the output `position` value). This is usually the result of a ill-formed expression, and the `make_token()` function will return `false`, indicating that the lexical analysis failed.

#### Implementing lexical analysis of arithmetic expressions

You need to accomplish the following.

* Add rules for the various token types in an arithmetic expression. You need to be aware of the presence of escape characters in C strings and the function of metacharacters in regular expressions.
* After successfully recognizing the token, record the information about the token into the `tokens` array in order.

#### Debugging axioms

*   The machine is always right.
    *   Corollary: If the program does not produce the desired output, it is the programmer's fault.
*   Every line of untested code is always wrong.
    *   Corollary: Mistakes are likely to appear in the "must-be-correct" code.

These two axioms mean: it's no use complaining, accept that the code is buggy, and be patient with debugging.

Jyy used to present them as facts. In fact, countless programmers (including seniors at your school) have proven them correct over and over again in practice, so here we present them as axioms.

#### How to debug

* Don't use " gaze debugging ", think about how to use the right tools and methods to help debugging.
    * Staring at dozens of lines of program in programming class, you may be able to simulate the execution of the program in your brain like NEMU; but after the program gets bigger, you'll soon give up: your brain can't simulate a huge state machine.
    * We learn about computers to learn how they work, not how to work mechanically like a computer.
* Use `assert()` to set up checkpoints, to intercept unintended situations.
    * For example, `assert(p ! = NULL)` can block segmentation errors caused by null pointer dereferences.
* Use `printf()` to see how a program is executing in conjunction with an understanding of its behavior (note the line breaks in the strings)
    * `printf()` outputs an arbitrary message that can be used to check code reachability: the corresponding message is output, if and only if the corresponding block of code is executed.
* `printf()` outputs the value of a variable can check how and why it has changed.
* Use GDB to observe arbitrary state and behavior of a program.
    * Print variables, breakpoints, watchpoints, function call stacks...

If the above suddenly makes sense to you, it means you didn't get the training you needed in your programming class.

#### Why does the output of printf() need line breaks?

What might happen if there were no line breaks? You can try it out in code, think about why, and then STFW to compare your ideas.

#### The Golden Rule of System Design -- The KISS Rule

The `KISS` here is an abbreviation for `Keep It Simple, Stupid`, which translates to: Don't Strive for Absolute Perfection in the Beginning.

You've learned the basics of programming, which means you've learned to write programs, but that doesn't mean you're ready for PA just yet, because in the real world, we need systems that work, not little programs that find factorials. NEMU is a small system with a code size of more than 3000 lines (excluding blank lines). As the PA progresses, the amount of code will be increasingly large, and the interaction between modules will be more and more complex, and the maintenance of the project will become very difficult, and a very retarded bug may need to be debugged for several days. In this case, the system can work is the king, anything not functional is useless. The pursuit of everything will only increase the difficulty of code maintenance.

The only thing that can save you from the chaos of bugs is the KISS rule, which is about **from easy to hard, step by step**, one thing at a time, and fewer irrelevant things. If you don't know what this means, let's take the `str` member buffer overflow problem mentioned above as an example. The KISS rule tells you that you should use `assert(0)`, which, even if it doesn't handle the above problem "properly", still doesn't affect the correctness of the core function of expression evaluation. If you remember the debugging axiom, you'll see that the two are related: the second point of the debugging axiom tells you that untested code is always wrong. Instead of writing so much "wrong" code all at once, you can use `assert(0)` to help minimize these "mistakes".

If you interpret the KISS rule in the context of software engineering, it emphasizes the importance of doing [unit tests](https://en.wikipedia.org/wiki/Unit_testing): write a function, test it, write the next function and test it again ... A good way to test is to use assertions, `reg_test()` is an example. Learning how to use assertions can be beneficial for both testing and debugging your program.

The KISS rule is widely used not only in computing, but in many other fields as well, and [here](http://blog.sciencenet.cn/blog-414166-562616.html) is an article with many examples, which we highly recommend you read, to realize the importance of the KISS rule. 

#### [#](#Recursive-evaluation) Recursive evaluation

Once the tokens in the expression have been recognized, we can proceed with the evaluation. Note that we are now working with an array of tokens, which we will refer to as a "token expression" for convenience. For example, the expression to be evaluated is

    "4 +3*(2- 1)"
    

has the token expression

    +-----+-----+-----+-----+-----+-----+-----+-----+-----+
    | NUM | '+' | NUM | '*' | '(' | NUM | '-' | NUM | ')' |
    | "4" |     | "3" |     |     | "2" |     | "1" |     |
    +-----+-----+-----+-----+-----+-----+-----+-----+-----+
    

By the inductive definition nature of expressions, we can easily use recursion to evaluate them. First we give the inductive definition of an arithmetic expression.

    <expr> ::= <number> # a number is an expression
      | "(" <expr> ")" # Adding parentheses to both sides of an expression is also an expression
      | <expr> "+" <expr> # Adding two expressions is also an expression
      | <expr> "-" <expr> # Next you get it all!
      | <expr> "*" <expr> 
      | <expr> "/" <expr> 
    

The above representation is the well-known [BNF](https://en.wikipedia.org/wiki/Backus%E2%80%93Naur_Form), which is used by any formal programming language tutorial to give the syntax of the programming language.

Based on the above BNF definition, a solution has developed: since a long expression is composed of short expressions, we evaluate the short expression first, and then evaluate the long expression. This natural solution is the application of [divide-and-conquer](https://en.wikipedia.org/wiki/Divide_and_conquer_algorithms), which is easy to understand even if you haven't heard of this fancy term. And to implement this solution, recursion is the way to go.

To indicate a sub-expression in a token expression, we can use two integers `p` and `q` to indicate where the sub-expression starts and where it ends. This makes it easy to write out the framework of the evaluation function: `p` and `q`.

    eval(p, q) {
      if (p > q) {
        /* Bad expression */
      }
      else if (p == q) {
        /* Single token.
         * For now this token should be a number.
         * Return the value of the number.
         */
      }
      else if (check_parentheses(p, q) == true) {
        /* The expression is surrounded by a matched pair of parentheses.
         * If that is the case, just throw away the parentheses.
         */
        return eval(p + 1, q - 1);
      }
      else {
        /* We should do more things here. */
      }
    }
    

The `check_parentheses()` function is used to determine if an expression is surrounded by a matching pair of parentheses, and to check if the left and right parentheses of an expression match; if they don't match, the expression is ungrammatical, and there's no need to continue evaluating it. Let's see some examples of what the `check_parentheses()` function can do:

    "(2 - 1)"             // true
    "(4 + 3 * (2 - 1))"   // true
    "4 + 3 * (2 - 1)"     // false, the whole expression is not surrounded by a matched
                          // pair of parentheses
    "(4 + 3)) * ((2 - 1)" // false, bad expression
    "(4 + 3) * (2 - 1)"   // false, the leftmost '(' and the rightmost ')' are not matched
    

As for how to check if the left and right parentheses match, let's leave that as a programming assignment for you to think about!

The above framework has considered the first two definitions of arithmetic expressions in BNF, and we'll consider the remaining cases (i.e., what's in the last `else` in the pseudo-code above). One question is, given a long expression whose leftmost and rightmost sides are not both parentheses, how do we properly split it into two sub-expressions? We define the "main operator" as the operator that is run at the last step of the expression when it is evaluated manually, which indicates the type of the expression (e.g. when the last step of an expression is a subtraction operation, it is essentially a subtraction expression). To split a long expression correctly is to find its main operator. We'll continue to explore this issue using the example above.

    "4 + 3 * ( 2 - 1 )"
    /*********************/
    case 1:
        "+"
       /   \
    "4"     "3 * ( 2 - 1 )"
    
    
    case 2:
            "*"
           /   \
    "4 + 3"     "( 2 - 1 )"
    
    
    case 3:
                  "-"
                 /   \
    "4 + 3 * ( 2"     "1 )"
    

The three possible splits are listed above, and note that we cannot split at a token that is not an operator, otherwise the result of the split would not be a legal expression. Based on the definition of the main operator, it is easy to see that only the first split is correct. This is consistent with our manual evaluation process: we first calculate `4` and `3 * ( 2 - 1 )`, and then we add their results. The second kind of splitting violates the priority of arithmetic operations, and causes addition to take place before multiplication. The third type of splitting destroys the balance of the parentheses. So the result of the 2nd and 3rd splitting is not a legal expression.

With the simple example above, we can summarize how to find the main operator in a token expression: 

* A token that is not an operator is not a main operator.
* A token that appears in a pair of parentheses is not a principal operator. Notice that there are no parentheses enclosing the entire expression, because this is handled in the corresponding `if` block of `check_parentheses()`. 
* The main operator has the lowest precedence in the expression. This is because the main operator is the last operator to be performed.
* When more than one operator has the lowest priority, the last operator to be combined is the main operator by combinability. An example would be `1 + 2 + 3`, whose main operator would be `+` on the right.

To find the main operator, just loop through the token expression and uniquely identify the main operator as described above.

Once you've found the correct main operator, it's a simple matter of recursively evaluating the two split sub-expressions, and then evaluating the main operator on the values of the two sub-expressions. The complete evaluation function is then as follow:

    eval(p, q) {
      if (p > q) {
        /* Bad expression */
      }
      else if (p == q) {
        /* Single token.
         * For now this token should be a number.
         * Return the value of the number.
         */
      }
      else if (check_parentheses(p, q) == true) {
        /* The expression is surrounded by a matched pair of parentheses.
         * If that is the case, just throw away the parentheses.
         */
        return eval(p + 1, q - 1);
      }
      else {
        op = the position of 主运算符 in the token expression;
        val1 = eval(p, op - 1);
        val2 = eval(op + 1, q);
    
        switch (op_type) {
          case '+': return val1 + val2;
          case '-': /* ... */
          case '*': /* ... */
          case '/': /* ... */
          default: assert(0);
        }
      }
    }
    

需要注意的是, 上述框架中并没有进行错误处理, 在求值过程中发现表达式不合法的时候, 应该给上层函数返回一个表示出错的标识, 告诉上层函数"求值的结果是无效的". 例如在`check_parentheses()`函数中, `(4 + 3)) * ((2 - 1)`和`(4 + 3) * (2 - 1)`这两个表达式虽然都返回`false`, 因为前一种情况是表达式不合法, 是没有办法成功进行求值的; 而后一种情况是一个合法的表达式, 是可以成功求值的, 只不过它的形式不属于BNF中的`"(" <expr> ")"`, 需要使用主运算符的方式进行处理, 因此你还需要想办法把它们区别开来. 当然, 你也可以在发现非法表达式的时候使用`assert(0)`终止程序. 不过这样的话, 你在使用表达式求值功能的时候就要十分谨慎了.

最后, 为了方便统一, 我们认为所有结果都是`uint32_t`类型.

#### 实现算术表达式的递归求值

由于ICS不是算法课, 我们已经把递归求值的思路和框架都列出来了. 你需要做的是理解这一思路, 然后在框架中填充相应的内容. 实现表达式求值的功能之后, `p`命令也就不难实现了.

#### 实现带有负数的算术表达式的求值 (选做)

在上述实现中, 我们并没有考虑负数的问题, 例如

    "1 + -1"
    "--1"    /* 我们不实现自减运算, 这里应该解释成 -(-1) = 1 */
    

它们会被判定为不合法的表达式. 为了实现负数的功能, 你需要考虑两个问题:

*   负号和减号都是`-`, 如何区分它们?
*   负号是个单目运算符, 分裂的时候需要注意什么?

你可以选择不实现负数的功能, 但你很快就要面临类似的问题了.

#### 从表达式求值窥探编译器

你在程序设计课上已经知道, 编译是一个将高级语言转换成机器语言的过程. 但你是否曾经想过, 机器是怎么读懂你的代码的? 回想你实现表达式求值的过程, 你是否有什么新的体会?

事实上, 词法分析也是编译器编译源代码的第一个步骤, 编译器也需要从你的源代码中识别出token, 这个功能也可以通过正则表达式来完成, 只不过token的类型更多, 更复杂而已. 这也解释了你为什么可以在源代码中插入任意数量的空白字符(包括空格, tab, 换行), 而不会影响程序的语义; 你也可以将所有源代码写到一行里面, 编译仍然能够通过.

一个和词法分析相关的有趣的应用是语法高亮. 在程序设计课上, 你可能完全没有想过可以自己写一个语法高亮的程序. 事实是, 这些看似这么神奇的东西, 其实也没那么复杂, 你现在确实有能力来实现它: 把源代码看作一个字符串输入到语法高亮程序中, 在循环中识别出一个token之后, 根据token类型用不同的颜色将它的内容重新输出一遍就可以了. 如果你打算将高亮的代码输出到终端里, 你可以使用[ANSI转义码的颜色功能](https://en.wikipedia.org/wiki/ANSI_escape_code#Colors).

在表达式求值的递归求值过程中, 逻辑上其实做了两件事情: 第一件事是根据token来分析表达式的结构(属于BNF中的哪一种情况), 第二件事才是求值. 它们在编译器中也有对应的过程: 语法分析就好比分析表达式的结构, 只不过编译器分析的是程序的结构, 例如哪些是函数, 哪些是语句等等. 当然程序的结构要比表达式的结构更复杂, 因此编译器一般会使用一种标准的框架来分析程序的结构, 理解这种框架需要更多的知识, 这里就不展开叙述了. 另外如果你有兴趣, 可以看看C语言语法的BNF.

和表达式最后的求值相对的, 在编译器中就是代码生成. ICS理论课会有专门的章节来讲解C代码和汇编指令的关系, 即使你不了解代码具体是怎么生成的, 你仍然可以理解它们之间的关系. 这是因为C代码天生就和汇编代码有密切的联系, 高水平C程序员的思维甚至可以在C代码和汇编代码之间相互转换. 如果要深究代码生成的过程, 你也不难猜到是用递归实现的: 例如要生成一个函数的代码, 就先生成其中每一条语句的代码, 然后通过某种方式将它们连接起来.

我们通过表达式求值的实现来窥探编译器的组成, 是为了落实一个道理: 学习汽车制造专业不仅仅是为了学习开汽车, 是要学习发动机怎么设计. 我们也强烈推荐你在将来修读"编译原理"课程, 深入学习"如何设计发动机".

### [#](#如何测试你的代码) 如何测试你的代码

你将来是要使用你自己实现的表达式求值功能来帮助你来进行后续的调试的, 这意味着程序设计课上那种"代码随便测试一下就交上去然后就可以撒手不管"的日子已经一去不复返了. 测试需要测试用例, 通过越多测试, 你就会对代码越有信心. 但如果让你来设计测试用例, 设计十几个你就会觉得没意思了, 有没有一种方法来自动产生测试用例呢?

一种常用的方法是[随机测试](https://en.wikipedia.org/wiki/Random_testing). 首先我们需要来思考如何随机生成一个合法的表达式. 事实上, 表达式生成比表达式求值要容易得多. 同样是上面的BNF, 我们可以很容易写出生成表达式的框架:

    void gen_rand_expr() {
      switch (choose(3)) {
        case 0: gen_num(); break;
        case 1: gen('('); gen_rand_expr(); gen(')'); break;
        default: gen_rand_expr(); gen_rand_op(); gen_rand_expr(); break;
      }
    }
    

你应该一眼就能明白上述代码是如何工作的: 其中`uint32_t choose(uint32_t n)`是一个很简单又很重要的函数, 它的作用是生成一个小于`n`的随机数, 所有随机生成的内容几乎都是通过它来选择的.

有了这些随机表达式作为测试输入, 我们怎么知道输出对不对呢? 如果要我们把这些表达式手动算一遍, 那就太麻烦了. 如果可以在生成这些表达式的同时, 也能生成它们的结果, 这样我们就能得到类似OJ的测试用例啦! 但我们在NEMU中实现的表达式求值是经过了一些简化的, 所以我们需要一种满足以下条件的"计算器":

*   进行的都是无符号运算
*   数据宽度都是32bit
*   溢出后不处理

嘿! 如果我们把这些表达式塞到如下C程序的源文件里面:

    #include <stdio.h>
    int main() {
      unsigned result = ???; // 把???替换成表达式
      printf("%u", result);
      return 0;
    }
    

然后用gcc编译它并执行, 让它输出表达式的结果, 这不就是我们想要的"计算器"吗?

还真能这样做! 我们已经准备好这个表达式生成器的框架代码了(在`nemu/tools/gen-expr/gen-expr.c`中). 你需要实现其中的`void gen_rand_expr()`函数, 将随机生成的表达式输出到缓冲区`buf`中. `main`函数中的代码会调用你实现的`gen_rand_expr()`, 然后把`buf`中的随机表达式放入上述C程序的代码中. 剩下的事情就是编译运行这个C程序了, 代码中使用了`system()`和`popen()`等库函数来实现这一功能. 最后, 框架代码将这个C程序的打印结果和之前随机生成的表达式一同输出, 这样就生成了一组测试用例.

#### 表达式生成器如何获得C程序的打印结果?

代码中这部分的内容没有任何注释, 聪明的你也许马上就反应过来: 竟然是个RTFM的圈套! 阅读手册了解API的具体行为可是程序员的基本功. 如果觉得去年一整年的程序员都白当了, 就从现在开始好好锻炼吧.

不过实现的时候, 你很快就会发现需要面对一些细节的问题:

*   如何保证表达式进行无符号运算?
*   如何随机插入空格?
*   如何生成长表达式, 同时不会使`buf`溢出?
*   如何过滤求值过程中有除0行为的表达式?

这些问题大多都和C语言相关, 就当作是C语言的又一个编程练习吧.

#### 为什么要使用无符号类型? (建议二周目思考)

我们在表达式求值中约定, 所有运算都是无符号运算. 你知道为什么要这样约定吗? 如果进行有符号运算, 有可能会发生什么问题?

#### 除0的确切行为

如果生成的表达式有除0行为, 你编写的表达式生成器的行为又会怎么样呢?

#### 过滤除0行为的表达式

乍看之下这个问题不好解决, 因为框架代码只负责生成表达式, 而检测除0行为至少要对表达式进行求值. 结合前两个蓝框题的回答(前提是你对它们的理解都足够深入了), 你就会找到解决方案了, 而且解决方案不唯一喔!

#### 实现表达式生成器

根据上文内容, 实现表达式生成器. 实现后, 就可以用来生成表达式求值的测试用例了.

    ./gen-expr 10000 > input
    

将会生成10000个测试用例到`input`文件中, 其中每行为一个测试用例, 其格式为

    结果 表达式
    

再稍微改造一下NEMU的`main()`函数, 让其读入`input`文件中的测试表达式后, 直接调用`expr()`, 并与结果进行比较. 为了容纳长表达式的求值, 你还需要对`tokens`数组的大小进行修改.

随着你的程序通过越来越多的测试, 你会对你的代码越来越有信心.

#### 温馨提示

PA1阶段2到此结束.

[基础设施: 简易调试器](/docs/ics-pa/1.4.html) [监视点](/docs/ics-pa/1.6.html)
